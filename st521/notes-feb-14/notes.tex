\documentclass{article}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{amsmath}
\begin{document}

Notes - 14 feb

$X_n$: S = {0, 1, ..., r-1, r, ..., N} (0 - r-1 transient, r - N absorbing).
Recall from last time: g(i) = "rate" to transient state i.
Let $W_i = E ( \Sigma_{n=0}^{T-1} g(X_n)|X_0=i)$. g(i)=1 $\Rightarrow \Sigma_{n=0}^{T-1}g(X_n)=T$.
ex 2.3.4 - if g(i) = 1 if i=k, 0 i not = k, k = transient state, gives $W_i = W_{ik}$, mean number of visits to state k before being absorbed.
Note: $\Sigma_{n=0}^{T-1}g(X_n)$ always includes $g(X_0)=g(i)$.
If a transition is made from state i to a transient state j, the sum will include some future terms. The Markov property implies the future sum proceeding from state j has value $W_j$.
Using the total law of probability, (2.3.3) $W_i = g(i) + \Sigma_{j=0}^{r-1}P_{ij}W_j, i=0, 1, 2, ..., r-1$.
exercise: explain this.
Example 2.3.5 - In ex 2.3.3, g(i) = 1 for all i. This implies that $\nu_i = E(T|X_0=i)=W_i$, and (2.3.4) $\nu_i = 1 + \Sigma_{j=0}^{r-1}P_{ij}V_j, i=0, 1, ..., r-1$.
Ex 2.3.6 - in ex 2.3.4, (2.3.5) $W_{ik} = \delta_{ik} + \Sigma_{j=0}^{r-1}P_{ij}W_{jk}, i=0, 1, ..., r-1$.
Example 2.3.7 - A Markov chain has P= (1, 0, 0, 0 \& .1, .4, .4, .1 \& .2, .1, .6, .1 \& 0, 0, 0, 1), S={0, 1, 2, 3}. Start in state 1. Determine probability of being absorbed into state 0, and mean time until absorption. 0, 3 absorbing states. 1, 2 transient. With $U_{i0}$ = P(absorption into 0 $| X_0 = i$). (2.3.2) gives: $U_{10} = P_{10} + P_{11}U_{10} + P_{12}U_{20}. U_{20} = P_{20} + P_{21}U_{10} + P_{22}U_{20}. U_{10} = .1 + .4 U_{10} + .1 U_{20}. U_{20} = .2 + .1 U_{10} + .6 U_{20}. \Rightarrow U_{10} = 6/23, U_{20} = 13/23. (2.3.4) \nu_1 = 1 + .4 \nu_1 + .1 \nu_2. \nu_2 = 1 + .1 \nu_1 + .6 \nu_2. \Rightarrow \nu_1 = 50/23, \nu_2 = 70/23.$

Section 2.4 - Gambler's Ruin
ex 2.1.2, 2.1.9 introduced random walks. $X_n$ = location.
Def 2.4.1 - if $r_i = 0, p_i = p, q_i = q (q = 1-p)$, this is a simple random walk.
ex 2.4.1 - gambler's ruin - We have a game for two people A, B. Total fortune of A and B is \$N. At each step i, A has probability $p_i$ of winning \$1, $q_i$ of losing \$1, and $r_i$ of drawing. $0 < p_i, q_i < 1, 0 \le r_i < 1, p_i + q_i + r_i = 1$. If A's fortune reaches 0 or N, game stops. Let $X_n$ = fortune of A at time n. $X_n$ is a Markov chain. P = (1, 0, 0, ... \& $q_1, r_1, p_1$, 0, ... \& 0, $q_2, r_2, p_2$, 0, ... \& ... \& 0, ..., $q_{N-1}, r_{N-1}, p_{N-1}$ \& 0, ..., 0, 1). States k=0, N are absorbing.

We address some intermediate time questions using (2.3.2), (2.3.4).
ex 2.4.3 - the probability of ruin for player A starting with \$i in ex 2.4.1 is $U_i = U_{i0}$ in (2.3.2), (2.4.1) $U_i = P_i U_{i+1} + r_i U_i + q_i U_{i-1}, i=1, 2, ..., N-1$, with boundary conditions $U_0 = 1, U_N = 0$. We can find an explicit formula for the solution in some cases.

ex 2.4.4 - assume $r_i = 0, p_i = p, q_i = q, q = 1-p$. (2.4.1) becomes (2.4.2) $U_i = p U_{i+1} + q U_{i-1} for 1 \le i \le N-1, U_0=1, U_N=0$. We look for a solution in the form $U_i = \Theta^i$. $\Theta^i = p \Theta^{i+1} + q \Theta^{i-1}, \Theta \ne 0 \Rightarrow \Theta = p \Theta^2 + q$. This has roots $\Theta_1 = 1, \Theta_2 = q/p$. If $p \ne 1/2, \Theta_1 \ne \Theta_2$. The general solution is a linear combination $U_i = A_1 \Theta_1^i + A_2 \Theta_2^i$. $A_1, A_2$ are constants. Using the boundary conditions, $U_0 = 1 = A_1 + A_2, U_N = 0 = A_1 + A_2 \frac{p}{q}^N \Rightarrow $ (2.3.4) $U_i = \frac{(q/p)^i - (q/p)^N}{1 - (p/q)^N}, p \ne 1/2, 0 < i < N$. If $p = 1/2, \Theta_1 = \Theta_2 = 1$, (2.4.4) $U_i = 1 - i/N, 0 < i < N$. For mean time to absorption, (2.3.4) becomes (2.4.5) $\nu_i = 1 + p \nu_{i+1} + q \nu_{i-1}, \nu_0 = \nu_N = 0 \Rightarrow$ (2.3.6) $\nu_i = \frac{1}{q-p} (i - N ( \frac {1 - (q/p)^i}{1 - (q/p)^N})) when p \ne 1/2, i(N-i) when p = 1/2$.

ex 2.4.5 - Suppose in ex 2.4.1 that A has a backer that guarantees A's losses. There is no ruin when A's fortune reaches 0. We can let P = ($q_0, p_0, 0$, ... \& $q_1, r_1, p_1$, ..., \& ...). If $p_i = p, q_i = q$, for all i, the absorbing times satisfy (2.4.5) again, but $\nu_N = 0, \nu_0: p \nu_0 = 1 + p \nu_1$. $q_0 = 0, r_0 + p_0 = 1$.

Section 2.5 - Simple Branching Processes
Model for evolution of a population. We start at time 0 with a progenitor. At the first time, the progenitor splits into k offspring with probability $p_k$, where {$p_k$} is a pmf, and then dies immediately. We assume the offspring reproduce in the same way. Process continues until extinction - when a generation produces no offspring. Let $X_n = $ population at time n.
Def 2.5.1, $X_n$ is a branching process.
Theorem 2.5.1, $X_n$ is a Markov chain.
Example 2.5.1 - Neutron Chain Reaction - A nucleus is split by a chance collision with a neutron and it releases a random number of new neutrons. These may hit other nuclei and cause further fission.

\end{document}
