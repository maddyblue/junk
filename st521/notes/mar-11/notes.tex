\documentclass{article}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{amsmath}
\begin{document}

Notes - 11 Mar

State $i$ is recurrent: $P(X_n=i$ some $n \ge 1|X_0=i)=1$. $i$ is transient: $P(X_n=i$ some $n \ge 1|X_0=i) < 1$. $f_{ij}(n) = P(X_1 \ne j, X_2 \ne j, \dots, X_n \ne j, X_n=j|X_0=i). f_{ij} = \Sigma_{n=1}^\infty f_{ij} (n)$. $j$ is recurrent $\iff f_{jj} = 1$.

Theorem - $j$ is recurrent if $\Sigma_n P_{jj}^n = \infty$. $j$ is transient if $\Sigma_n P_{jj}^n < \infty$.

$T_j = $min$\{n \ge 1: X_n=j\}$. time of first visit to $j (X_0=i). P(T_i = \infty | X_0=i) > 0 \iff i$ is transient. $\mu_i = E(T_i | X_0=i) = \{ \Sigma_{n=1}^\infty f_{ii}(n)$ for i recurrent, $\infty$ for i transient. Recurrent state is null if $\mu_i = \infty$. Recurrent state is positive if $\mu_i < \infty$.

Theorem - Recurrent state is null iff $P_{ii}^n \rightarrow 0$ as $n \rightarrow \infty$.

etc, more review...

New stuff:

Example 3.2.8 - $S = \{0, 1, 2, 3, 4, 5\}$. \begin{displaymath} P = \left( \begin{array}{cccccc} 1/2 & 1/2 & 0 & 0 & 0 & 0 \\ 1/4 & 3/4 & 0 & 0 & 0 & 0 \\ 1/4 & 1/4 & 1/4 & 1/4 & 0 & 0 \\ 1/4 & 0 & 1/4 & 1/4 & 0 & 1/4 \\ 0 & 0 & 0 & 0 & 1/2 & 1/2 \\ 0 & 0 & 0 & 0 & 1/2 & 1/2 \end{array} \right) \end{displaymath}. $\{0, 1\}, \{4, 5\}$ irreducible and closed. Therefore contain positive recurrent states. 2, 3 are transient: $2 \rightarrow 3 \rightarrow 5$. But return to 2 or 3 from 5 is impossible. $T = \{2, 3\}, C_1 = \{0, 1\}, C_2 = \{4, 5\}$. All states have period 1 since $P_{ii} > 0$ for all i (all entries on diagonal $> 0$). 0, 1, 4, 5 are ergodic. We can compute $f_0(1) = P_{00} = 1/2, f_{00}(n) = P_{01} (P_{11})^{n-2} P_{10} = 1/2 (3/4)^{n-2} 1/4, n \ge 2. \mu_0 = \Sigma_n f_{00}(n) * n = 3$.

Example 3.2.9 - Success Runs - $S = \{0, 1, \dots \}$. P = (q0 p0 0 ... \& q1 0 p1 0 ... \& q2 0 0 p2 0 ... \& ... ). $q_{ii} p_i \ge 0, q_i + p_i = 1$ for all $i$. This is a success run chain. Intuition: assume $p_i = p$ for all $i$. We attempt independent Bernoulli trials with probability $p$ of success. We count the number of successful trials in a row. If we had $n$ successes in a row, we can extend the run to $n + 1$ if we have success on the next trial or we start over with a run of 0 if we fail in the next trial. This gives the row (q(0th) 0 ... p((n+1)st) 0 ...). We assume $0 < p_i < 1$ for all $i$ so the chain is irreducible. This means state $i$ is recurrent iff state 0 is recurrent. We have $f_{00}(1) = q_0$, and for $n \ge 2, f_{00}(n) = P(X_1=1, X_2=2, \dots, X_{n-1}=n-1, X_n=0|X_0=0) = P_0 P_1 P_2 \dots P_{n-2} * q_{n-1}$. Set $U_n = \Pi_{i=0}^n P_i, n \ge 0$ since $q_{n-1} = 1 - P_{n-1}, f_{00}(n) = U_{n-2} - U_{n-1} = \Pi_{i=0}^{n-2} P_i(1 - P_{n-1})$. So $\Sigma_{n=1}^{N+1} f_{00}(n) = q_0 + (U_0 - U_1) + \dots + (U_{N-1} - U_N) = q_0 + U_0 - U_N = 1 - U_N$. 0 is recurrent iff $U_N = \Pi_{i=0}^N Pi \rightarrow 0$ as $N \rightarrow \infty$. L'Hopital's rule implies that if $0 < P_i < 1$ for all $i, U_N = \Pi_{i=0}^N P_i \rightarrow 0 \iff \Sigma_{i=0}^\infty (1-P_i) = \infty. \Pi_{i=0}^\infty P_i > 0 \iff \Sigma_{i=0}^\infty (1-P_i) < \infty$. 0 is recurrent iff $\Sigma_{i=0}^\infty (1-P_i) = \infty$, or the $P_i$'s cannot be too close to 1. If $P_i = 1 - (1/2)^i$, not recurrent. $P_i$ constant then recurrent. (Chapter IV, section $\S$3 in text.)

$\S$ 3.3 - Stationary distributions and the limit theorem

We consider behavior as $n \rightarrow \infty$. Does the distribution of $X_n$ converge to something?

Example 3.3.1 - ON/OFF system - ex 2.2.3 - P = ($1-p$, p \& q, $1-q$). $P^n$ as before. $0 < p < 1, 0 < q < 1, P^n \rightarrow \frac{1}{p + q} * $(q p \& q p) [as before]. We choose the initial state $X_0$ according to the probabilities $P(X_0 = 0) = \nu_0, P(X_0=1) = \nu_1 = 1 - \nu_0$.

Definition 3.3.1 - An initial distribution is a probability distribution for the initial state of a Markov chain. The probability distribution of $X_1$, conditioned on $X_0$ is $P(X_1=j|X_0) = P_{0j} \nu_0 + P_{ij} \nu_1, j = 0, 1$. Matrix notation $(P(X_1=0|X_0) P(X_1=1|X_0)) = \nu p$. Suppose we take $\nu_0 = \frac{q}{q + p}, \nu_1 = \frac{p}{q+p}$. If we compute, $P(X_1=0) = (1-p) \frac{q}{q+p} + q \frac{p}{q+p} = \frac{q}{p+q} = \nu_0$ and $P(X_1=1) = \nu_1$. In matrix notation $\nu = \nu p$. That particular initial distribution does not change over time.

Definition 3.3.2 - Let $S$ = state space, The vector $\Pi$ is a stationary distribution if $\Pi = (\Pi_i)_{i \in S}$ satisfies (1) $\Pi_i \ge 0$ all i, $\Sigma_{i \in S} \Pi_i = 1$, (2) $\Pi = \Pi P(\Pi_j = \Sigma_{i \in S} \Pi_i P_{ij}$ all $j \in S)$. P = probability transition matrix. These are also called invariant distributions and equilibrium distributions.

Theorem 3.3.1 - If $\Pi$ is a stationary distribution, (3.3.1) $\Pi P^n = \Pi$ for all $n \ge 0$. If $X_0$ has distribution $\Pi$, then so does $X_n$ for $n \ge 0$. Proof: exercise.

Aside: long time behavior of ODE's $\dot y = f(y)$. Stead-state/equilibrium solutions $f(y_s) = 0 \Rightarrow y_s $ constant, $\dot y_s = f(y_s) = 0$.

We assume the chain is irreducible and explore the existence of stationary distributions.

Example 3.3.2 - Consider ex 3.3.1 (ON/OFF), $\Pi = \Pi P = (\Pi_0 \Pi_1) $($1-p$, p \& q, $1-q$)$ = (\Pi_0 \Pi_1) \Rightarrow \Pi_1 = p/q \Pi_0$ (1st equation), $\Pi_1 = p/q \Pi_0$ (2nd equation), $\Pi_0 + \Pi_1 = 1 \Rightarrow \Pi = (\frac{q}{p+q}, \frac{p}{p+q})$.

\end{document}
