\documentclass{article}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage{amsmath}
\begin{document}

Notes - 1 April

Review from a question in class: why did we need a PGF last time? 1) Basic problem: finding $\Pi = \Pi P, \Pi$ pmf. $\Pi$ exists sometimes. Relation to being positive recurrent.  2) Basic problem: find a bounded solution of $Y = PY$ with a row/column ``missing'', related to transient. Then we got to ex 3.3.8 - classic example: queuing theory. This example had several points: 1) Consider $\Pi = \Pi P$. Used generating functions. Came to the conclusion that $\Pi$ exists $\iff \gamma = \Sigma_{k=0}^\infty k a_k < 1$, but only if chain is positive recurrent. So we needed to proved that the chain is positive recurrent so we can solve the problem. 2) We consider solution of $Y = PY, |Y_i| \le 1$, with missing row/column (not full $P$). It this case using the fixed point theory we prove $Y$ exists, but this holds iff chain is transient, which holds iff $\gamma > 1$. So, theorem is: positive recurrent if $\gamma < 1$, transient if $\gamma > 1$.

$\S 3.4$ - Limit Theorems

We explore the link between a stationary distribution and the behavior of $P_{ij}^n$ as $n \rightarrow \infty$.

Example 3.4.1 - Consider ON/OFF system in ex 2.2.3 with P = (1-p p \& q 1-q) $0 \le p \le 1, 0 \le q \le 1$. When $0 < p, q < 1, P^n \rightarrow \frac{1}{p+q}$(q p \& q p) and we know there is a stationary distribution. Now suppose $p = q = 1$, the system changes states at every step. The stationary distribution satisfies $(\Pi_0, \Pi_1) = (\Pi_0, \Pi_1)$(0 1 \& 1 0) $\Rightarrow \Pi_0 = \Pi_1 = 1/2$. We can compute, e.g. $P_{00}^n = \{$ 0 if n even, 1 if n odd. There is no limiting behavior in this case. However the states are periodic with period 2.

Theorem 3.4.1 - For an irreducible, aperiodic Markov chain, (3.4.1) $P_{ij}^n \rightarrow \frac{1}{\mu_j}$ as $n \rightarrow \infty$ for all $i, j$ ($\mu_j$ is the mean recurrence time). The limiting value is the same for all states $i$. $P^n \rightarrow$ (1/mu0 1/mu0 \dots \& 1/mu1 1/mu1 \dots \& \dots)$^T$ = (1/mu0 1/mu1 \dots \& 1/mu0 1/mu1 \dots \& \dots).

Definition 3.4.1 - If there is a probability distribution $q$ on the state space $S$ such that $P_{ij}^n \rightarrow q_j$ for all $i, j \in S$ then $q$ is a limit distribution of the chain.

Intuition: $q_j$ describes the probability that the chain is in state $j$ at some ``late'' time and by this time the chain has ``forgotten'' where it started. $P(X_n=j) = \Sigma_i P(X_0=i) P_{ij}^n \rightarrow q_j$ regardless of the initial distribution of $X_0$. Consequences:

Theorem 3.4.2 - (a) If the chain is transient or null recurrent, then $P_{ij}^n \rightarrow 0$ for all $i, j$. (b) If the chain is positive recurrent, then $P_{ij}^n \rightarrow \Pi_j = \mu_j^{-1}$, where $\Pi$ is the unique stationary distribution.

Theorem 3.4.3 - If $X_n$ is an irreducible chain with period $d$, then $Y_n = X_{nd}, n \ge 0$, is an aperiodic, irreducible chain, $P_{jj}^{nd} = P(Y_n=j | Y_0=j) \rightarrow \frac{d}{\mu_j}$ as $n \rightarrow \infty$. Immediately from this follows the proof of theorem 3.1.6 (see notes).

Connection between limiting and stationary distributions: consider a Markov chain at some ``late'' time $n$. The stationary distribution gives the proportion of time spent in the different states up to time $n$.

The limit distribution gives the proportion of ``time'' spent in the various states at the large time, where we count by considering many realizations.

Example 3.4.2 - Consider ON/OFF system, ex 3.4.1 again. The stationary distribution ($1/2, 1/2$) says that equal amounts of time are spent in each state up to some large time, say $n = 1000$. If we look precisely at $n = 1000$, the chain must return to its initial state. Multiple realizations give probability 1 to be in the initial state and 0 to be in the other.

Theorem 3.4.4 - An ergodic Markov chain has the property that it has both stationary and limiting distributions and these are equal.

Proof of theorem 3.4.1 - We treat different cases. The simplest case is a transient chain, because theorem 3.1.2 (3) implies $P_{ij}^n \rightarrow 0$ as $n \rightarrow \infty$ for all $i, j$. The recurrent cases are treated with ``coupling''.

Definition - 3.4.2 - Let $X_n, Y_n$ be independent Markov chains with common state space $S$ and common probability transition matrix $P$. The coupled chain $Z_n = (X_n, Y_n)$ taking values in $S \times S$.

Theorem 3.4.5 - $Z_n$ is a Markov chain with $P_{ij, kl} = P_{ik}P_{jl}$. If $X_n, Y_n$ are irreducible and aperiodic, then $Z_n$ is irreducible. Proof: $P_{ij, kl} = P(Z_{n+1} = (k, l) | Z_n = (i, j)) = P(X_{n+1} = k | X_n=i) \times P(X_{n+1} = l | Y_n = j). X_n, Y_n$ aperiodic, irreducible $\Rightarrow$ for any $i, j, k, l$ there is an $N = N(i, j, k, l)$ such that $P_{ik}^n P_{jl}^n > 0, n \le N$. Exercise: this implies $Z_n$ is irreducible.

Comment: this is the only place we use the assumption $X_n$ is aperiodic.

We assume $X_n$ (in thm 3.4.1) is positive recurrent, so it has unique stationary distribution $\Pi$. (Consider $Y = X$ in the construction of $Z$.) Exercise: $Z_n = (X_n, Y_n)$ has a stationary distribution $\nu = (\nu_{ij}, i, j \in S), \nu_{ij} = \Pi_i \Pi_j$. This implies $Z_n$ is also positive recurrent (due to stationary distribution). Choose $X_0 = i, Y_0 = j, Z_0 = (i, j)$. Choose $s \in S$. Set $T =$ min$(n \ge 1: Z_n = (s, s))$. The recurrence of $Z_n$ implies that $P(T < \infty) = 1$ (exercise).

\end{document}